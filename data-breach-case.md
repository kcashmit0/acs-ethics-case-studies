# Case Study: You Just Found a Massive Data Breach. Now What?

## The Situation

You're a junior developer at a healthcare startup. It's Tuesday afternoon, you're debugging some production code, and then you see it - patient medical records are just... sitting there. Publicly accessible. Anyone with the API endpoint can see them.

**The Details:**
- 50,000+ patient records exposed (names, diagnoses, medications - the whole lot)
- Been exposed for 6 months and nobody noticed
- You tell your manager. Their response? "Just quietly fix it and don't tell anyone"
- Patients have no idea their data's been sitting out there
- Oh, and the company's about to raise Series B funding next month

So now you're sitting there thinking: *What the hell do I do?*

## Who's Affected Here?

**The Patients** - Their private medical info is out there. Someone could've grabbed it, used it, sold it. They don't even know.

**The Company** - If this gets out, reputation's cooked. Legal liability. Funding? Probably toast.

**You** - Your job's probably on the line either way. Plus you're supposed to be a professional, right?

**The Healthcare System** - One more reason for people not to trust digital health records.

**The Investors** - They're about to drop millions on a company that left 50k records exposed for half a year.

**Regulators** - OAIC and state health departments will want a word.

## What Does the ACS Code Say?

### Public Interest Comes First
The ACS Code says you need to put public interest above your own interests and the company's. Patient privacy matters more than keeping your manager happy.

### Be Honest
You're supposed to be honest about situations that could harm stakeholders. 50,000 exposed patient records definitely qualifies.

### Know the Law
The Privacy Act 1988 and the Notifiable Data Breaches scheme aren't optional. You can't just "quietly fix it" and pretend it never happened.

## Your Options (Let's Be Real)

### Option 1: Do What Your Manager Said

**Why you might do it:**
- Keep your job (maybe)
- Company doesn't get embarrassed
- Vulnerability gets fixed

**Why this is a bad idea:**
- It's literally illegal under the Privacy Act
- Patients stay in the dark about their exposed data
- You're now part of a cover-up
- If it comes out later (and it probably will), you're screwed

**ACS Code says:** Hard no. This violates everything.

### Option 2: Go Over Your Manager's Head

**Why this might work:**
- Gives the company a chance to do the right thing
- You tried to handle it internally first
- Maybe you keep your job?

**The problems:**
- Upper management might just shut it down too
- Every day you wait, patients are still at risk
- Company culture clearly doesn't support this if your manager's already told you to hide it

**ACS Code says:** Better, but still not enough.

### Option 3: Report to OAIC and Notify Patients

**Why this is the right thing:**
- It's what the Privacy Act requires
- Patients can actually protect themselves
- You're doing your professional duty

**Why this sucks:**
- You're probably getting fired
- Company's going to be pissed
- They might even try to sue you

**ACS Code says:** This is what you're supposed to do, even though it's hard.

### Option 4: Document Everything, Give Company a Chance, Prepare to Go External

**The approach:**
- Document the vulnerability and your manager's instructions
- Give company 30 days to self-report (that's what the law requires anyway)
- If they don't, you report it yourself
- Keep records of everything to protect yourself

**Why this works:**
- Legal compliance
- You tried the internal route first
- You've got documentation if things go south
- Maintains your professional integrity

**ACS Code says:** This is compliant AND realistic.

## What You Should Actually Do

### Day 1 - Right Now

**1. Save Everything**
- Screenshot that vulnerability
- Save your manager's "quietly fix it" message (email, Slack, whatever)
- Document when you found it
- Send copies to your personal email

**2. Fix the Vulnerability**
- Stop the bleeding first
- But don't think this makes the problem go away

**3. Email the Higher-Ups**
- Go to CTO or CEO
- Subject: "Discovered Data Breach - Legal Obligation to Report"
- Keep it factual: "Found X exposed for Y months. Privacy Act requires reporting to OAIC within 30 days."
- CC your personal email

### Days 2-5 - If They Refuse

**4. Get Legal Advice**
- Talk to an employment lawyer about your rights
- Look into whistleblower protections

**5. Report to OAIC**
- If the company won't do it, you have to
- This is your professional obligation

**6. Document Your Reasoning**
- Reference the ACS Code
- Reference the Privacy Act
- Show you tried to do this the right way

### After That

**7. Start Job Hunting**
- Let's be realistic - you're probably getting fired
- But you can tell future employers you stood by your professional ethics

**8. Know Your Protections**
- Whistleblower protections exist under the Corporations Act
- Document everything in case you need it

## The Hard Truth

### What the Law Says
- Notifiable Data Breaches scheme: Report within 30 days. Not optional.
- Privacy Act: Tell the affected people. Also not optional.
- Criminal penalties for company officers who don't comply: Up to 2 years in prison.

### What Being a Professional Means
- Patient privacy beats company convenience
- Healthcare data gets special protection for a reason
- Your career matters, but so does your integrity

### The Reality Check
- "Quietly fixing it" is illegal AND unethical
- Company funding doesn't trump patient rights
- This is going to suck either way, but at least one way lets you sleep at night

## Questions to Think About

1. When does your loyalty to your employer end and your professional duty begin?
2. Should a junior dev really have to make this call, or is this management's problem?
3. How do we build companies where people can report this stuff without losing their jobs?
4. What actually protects whistleblowers in Australia? (Spoiler: Not enough)

## This Has Happened Before

- **Facebook-Cambridge Analytica** - 87 million users' data harvested
- **Australian Red Cross Blood Service (2016)** - 550,000 donor records exposed
- Both cases: Someone knew, and someone had to decide whether to speak up

## The Bottom Line

Your manager told you to cover this up. The law says you can't. The ACS Code says you can't. Your conscience probably says you can't.

Is it fair that you're in this position? No.

Is it fair that 50,000 patients don't know their medical records were exposed? Also no.

**The professional path means reporting this, even if it costs you your job. That's what the code means when it says "public interest first."**

It's going to suck. But at least you'll be able to look yourself in the mirror.

---

## References
- [ACS Code of Professional Conduct](https://www.acs.org.au/content/dam/acs/rules-and-regulations/Code-of-Professional-Conduct_v2.1.pdf)
- [OAIC Notifiable Data Breaches Scheme](https://www.oaic.gov.au/privacy/notifiable-data-breaches)
- [Privacy Act 1988](https://www.legislation.gov.au/Details/C2021C00452)
